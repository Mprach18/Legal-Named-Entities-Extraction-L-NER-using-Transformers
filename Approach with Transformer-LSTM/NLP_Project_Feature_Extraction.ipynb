{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0z5-X0-_Fko",
        "outputId": "3e575a72-ba48-4830-d9ce-b15e009d2763"
      },
      "outputs": [],
      "source": [
        "pip install -q git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgvIafx89wv1",
        "outputId": "a100af2e-39bb-44eb-b461-ff8a19eab840"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jes9Q9sEVwQj",
        "outputId": "2a582008-92a5-4607-a619-b15400405ab3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Final_DataFrame_Train.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJyWHptWVwQm",
        "outputId": "10e5cfef-556b-4178-f7e3-65cead4e9725"
      },
      "outputs": [],
      "source": [
        "train_sents = df['clean_sent'].to_list()\n",
        "train_labels = df['tags'].to_list()\n",
        "\n",
        "print(len(train_sents))\n",
        "print(len(train_labels))\n",
        "\n",
        "train_sents = [train_sents[i].replace(\"'\", \"\").strip(\n",
        "    '][').split(', ') for i in range(len(train_sents))]\n",
        "train_labels = [train_labels[i].replace(\"'\", \"\").strip(\n",
        "    '][').split(', ') for i in range(len(train_labels))]\n",
        "\n",
        "\n",
        "print(len(train_sents[0]))\n",
        "print(len(train_labels[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sV-tE-yVwQn",
        "outputId": "650573d6-3979-4d86-c530-255da5396d4f"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-small-uncased\")\n",
        "model = AutoModel.from_pretrained(\"nlpaueb/legal-bert-small-uncased\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLrzOU7KVwQn"
      },
      "outputs": [],
      "source": [
        "# def get_dict_map(labels):\n",
        "#     \"\"\"\n",
        "#     converts word to index\n",
        "\n",
        "#     [Need changes !!!]\n",
        "#     \"\"\"\n",
        "#     tok2idx = {}\n",
        "#     idx2tok = {}\n",
        "\n",
        "#     vocab = []\n",
        "#     for sent in labels:\n",
        "#       vocab.extend( list(set(sent)) )\n",
        "#     vocab = set(vocab)\n",
        "\n",
        "\n",
        "#     idx2tok = {idx:tok for idx , tok in enumerate(vocab)}\n",
        "#     tok2idx = {tok:idx for idx , tok in enumerate(vocab)}\n",
        "\n",
        "#     return tok2idx, idx2tok\n",
        "\n",
        "# tag2idx, idx2tag = get_dict_map(train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9m_hRntVwQn"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(train_sent, train_labels):\n",
        "    tokenized_input = tokenizer(train_sent, padding='max_length', max_length=512,\n",
        "                                truncation=True, return_tensors=\"pt\", is_split_into_words=True)\n",
        "\n",
        "    word_ids = tokenized_input.word_ids()\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            label_ids.append(0)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            label_ids.append(tag2idx[train_labels[word_idx]])\n",
        "        else:\n",
        "            label_ids.append(0)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    tokenized_input[\"labels\"] = label_ids\n",
        "    return tokenized_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H_T_dv-VwQo"
      },
      "outputs": [],
      "source": [
        "tokenized_input_and_labels = []\n",
        "for train_sent, train_label in zip(train_sents, train_labels):\n",
        "  # print(train_sent)\n",
        "  # print(train_label)\n",
        "\n",
        "  tokenized_input_and_labels.append(\n",
        "      tokenize_and_align_labels(train_sent, train_label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyzNQsOpVwQo",
        "outputId": "24fb4455-979c-4981-c627-de6ecd393dd6"
      },
      "outputs": [],
      "source": [
        "print(tokenized_input_and_labels[0]['input_ids'].shape)\n",
        "print(len(tokenized_input_and_labels[0]['labels']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxEQAdiMVwQp",
        "outputId": "3a03a124-a510-4fc2-982b-3a7f44a387c1"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "for i in range(len(tokenized_input_and_labels)):\n",
        "  labels.append(tokenized_input_and_labels[i]['labels'])\n",
        "  del tokenized_input_and_labels[i]['labels']\n",
        "\n",
        "print(len(labels[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwpQW2OGVwQp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "hidden_states = []\n",
        "for input in tokenized_input_and_labels:\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**input)\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    hidden_states.append(last_hidden_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4p25EndVwQq",
        "outputId": "12db5e25-60cd-48e6-9271-068383a4667c"
      },
      "outputs": [],
      "source": [
        "print(len(hidden_states))\n",
        "print(hidden_states[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-MrbPQWVwQq"
      },
      "outputs": [],
      "source": [
        "# Saving features and corresponding labels\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\"features\": hidden_states, \"labels\": labels})\n",
        "df.to_pickle(\"train_features_legalBert.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TRvRrcwVwQq",
        "outputId": "3d6e403d-d019-4fe3-edeb-051f95d42818"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTlMhjojVwQq"
      },
      "source": [
        "### Load Features and Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "nuZ13OXCVwQr",
        "outputId": "8f6362ec-8b79-4df5-9d8e-0cda19ae7e25"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('./bertFeatureExtraction1.pkl')\n",
        "\n",
        "features = df[['features']].to_numpy()\n",
        "all_labels = df[['labels']].to_numpy()\n",
        "all_features = []\n",
        "for i in range(len(df)):\n",
        "  all_features.append(features[i][0])\n",
        "\n",
        "print(len(all_features))\n",
        "print(all_features[0].shape)\n",
        "print(all_labels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('py39')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Jun  1 2022, 06:36:29) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d114e2fce53d8e9265a525cd978d04995f4f870c0dbcbfa2747259b3171028bc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
